# -*- coding: utf-8 -*-
"""CRAFT_text_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r08kEnANt_b9CyfbO_p36OppNTtqaS5E
"""

!pip uninstall -y torchaudio torchdata torchtext

!pip install torch==1.12.0 torchvision==0.13.0

!pip install craft-text-detector

import torch
import cv2
from craft_text_detector import Craft

from google.colab import drive
drive.mount('/content/drive')

image_path ='/content/drive/MyDrive/CRAFT/input1.png'
output_dir = '/content/drive/MyDrive/CRAFT'

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
plt.rcParams["axes.grid"] = False
image = mpimg.imread(image_path)
plt.imshow(image)

def detect(image_path,output_dir):
  # create a craft instance
  craft = Craft(output_dir=output_dir, crop_type="poly", cuda=False)

  # apply craft text detection and export detected regions to output directory
  prediction_result = craft.detect_text(image_path)

detect(image_path,output_dir)

import torch
import torchvision.models as models

vgg_model_urls = models.vgg.model_urls
print(vgg_model_urls)

import glob
from IPython.display import Image

image_paths = glob.glob('/content/drive/MyDrive/CRAFT/*.png')
print(image_paths)
Image(image_paths[3])

regionscore = mpimg.imread('/content/drive/MyDrive/CRAFT/input1_text_score_heatmap.png')

plt.imshow(regionscore)

if regionscore.shape[2] == 3:  # Color image
    regionscore = cv2.cvtColor(regionscore, cv2.COLOR_BGR2GRAY)

mask = regionscore > 0.5

plt.imshow(regionscore)

!pip install opencv-python
import numpy as np

contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

bounding_boxes = [cv2.boundingRect(cnt) for cnt in contours]

import torchvision
bounding_boxes = torchvision.ops.nms(boxes=torch.tensor(bounding_boxes), iou_threshold=0.2)